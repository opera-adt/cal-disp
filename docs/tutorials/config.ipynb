{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    " \n",
    "This tutorial covers the configuration system for the displacement calibration workflow.\n",
    "\n",
    "**Philosophy**: The config system uses Pydantic for validation at serialization boundaries. This means:\n",
    "- Type-safe configurations with automatic validation\n",
    "- Clear error messages when something is wrong\n",
    "- YAML files that map directly to Python objects\n",
    "- No scattered validation checks throughout the codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start: Minimal Configuration\n",
    "\n",
    "Let's start with the simplest possible config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration Workflow Configuration\n",
      "======================================================================\n",
      "\n",
      "Directories:\n",
      "  Work directory:   /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/work\n",
      "  Output directory: /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/output\n",
      "  Log file:         /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/work/cal_disp.log\n",
      "  Keep relative:    False\n",
      "\n",
      "Input Files:\n",
      "  Not configured!\n",
      "\n",
      "Worker Settings:\n",
      "  Workers:          4\n",
      "  Threads/worker:   2\n",
      "  Total threads:    8\n",
      "  Block shape:      (128, 128)\n",
      "\n",
      "Workflow Status: NOT READY\n",
      "Errors:\n",
      "  - input_options must be provided\n",
      "  - dynamic_ancillary_options must be provided\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from cal_disp.config.workflow import CalibrationWorkflow\n",
    "\n",
    "# Create minimal config - just directories\n",
    "config = CalibrationWorkflow.create_minimal()\n",
    "print(config.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This config isn't ready to run yet. It needs input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Adding Required Input Files\n",
    "\n",
    "Every workflow needs:\n",
    "1. A displacement file (DISP-S1 product)\n",
    "2. A calibration reference grid\n",
    "3. Dynamic ancillary files (DEM, LOS, masks, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to run: True\n"
     ]
    }
   ],
   "source": [
    "from cal_disp.config import DynamicAncillaryFileGroup, InputFileGroup\n",
    "\n",
    "# Set up input files\n",
    "config.input_options = InputFileGroup(\n",
    "    disp_file=Path(\"data/OPERA_L3_DISP-S1_T001-000001-IFG_20240101_20240113_v1.0.nc\"),\n",
    "    unr_grid_latlon_file=Path(\"data/grid_latlon_lookup_v0.2.txt\"),\n",
    "    unr_timeseries_dir=Path(\"data/unr_grid/\"),\n",
    "    frame_id=1,\n",
    "    unr_grid_version=\"0.2\",\n",
    "    unr_grid_type='constant',\n",
    ")\n",
    "\n",
    "# Set up dynamic ancillaries\n",
    "config.dynamic_ancillary_options = DynamicAncillaryFileGroup(\n",
    "    algorithm_parameters_file = Path(\"configs/algorithm_parameters.yaml\"),\n",
    "    static_dem_file=Path(\"data/dem.tif\"),\n",
    "    static_los_file=Path(\"data/line_of_sight_enu.tif\"),\n",
    ")\n",
    "\n",
    "# Check if ready to run\n",
    "status = config.validate_ready_to_run()\n",
    "print(f\"Ready to run: {status['ready']}\")\n",
    "if status['errors']:\n",
    "    print(\"Errors:\")\n",
    "    for error in status['errors']:\n",
    "        print(f\"  - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Working with YAML Files\n",
    "\n",
    "Configs are typically stored as YAML files. Here's the round-trip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to workflow_config.yaml\n",
      "\n",
      "YAML contents:\n",
      "# Configuration for required input files. Must be provided before running workflow.\n",
      "#   Type: None | None.\n",
      "input_options:\n",
      "  disp_file: data/OPERA_L3_DISP-S1_T001-000001-IFG_20240101_20240113_v1.0.nc\n",
      "  calibration_reference_latlon_file: data/unr3/grid_latlon_lookup_v0.2.txt\n",
      "  calibration_reference_grid_dir: data/unr3\n",
      "  frame_id: 8882\n",
      "# Directory for intermediate processing files. Created if it doesn't exist.\n",
      "#   Type: string.\n",
      "work_directory: /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/work\n",
      "# Directory for final output files. Created if it doesn't exist.\n",
      "#   Type: string.\n",
      "output_directory: /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/output\n",
      "# If False, resolve all relative paths to absolute paths. If True, keep paths as provided.\n",
      "#   Type: boolean.\n",
      "keep_paths_relative: false\n",
      "# Dynamic ancillary files (dem, los, masks, troposphere, etc.).\n",
      "#   Type: None | None.\n",
      "dynamic_ancillary_options:\n",
      "  algorithm_parameters_file: configs/algorithm_parameters.yaml\n",
      "  static_los_file: \n",
      "    data/static_input/OPERA_L3_DISP-S1-STATIC_F08882_20140403_S1A_v1.0_line_of_sight_enu.tif\n",
      "  static_dem_file: \n",
      "    data/static_input/OPERA_L3_DISP-S1-STATIC_F08882_20140403_S1A_v1.0_dem.tif\n",
      "  mask_file:\n",
      "  ref_tropo_files:\n",
      "  sec_tropo_files:\n",
      "  iono_files:\n",
      "  tiles_files:\n",
      "# Static ancillary files (algorithm overrides, databases, etc.).\n",
      "#   Type: None | None.\n",
      "static_ancillary_options:\n",
      "worker_settings:\n",
      "  # Number of workers to use in dask.Client. Typically set to the number of physical CPU cores\n",
      "  #   or less. Default: 4.\n",
      "  #   Type: integer.\n",
      "  n_workers: 4\n",
      "  # Number of threads per worker in dask.Client. Controls parallelism within each worker.\n",
      "  #   Default: 2.\n",
      "  #   Type: integer.\n",
      "  threads_per_worker: 2\n",
      "  # Size (rows, columns) of blocks of data to load at a time. Larger blocks use more memory\n",
      "  #   but may be more efficient. Must be positive integers. Default: (128, 128).\n",
      "  #   Type: array.\n",
      "  block_shape:\n",
      "    - 128\n",
      "    - 128\n",
      "# Path to output log file (in addition to logging to stderr). If None, defaults to\n",
      "#   'cal_disp.log' in work_directory.\n",
      "#   Type: string | None.\n",
      "log_file: /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/work/cal_disp.log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save to YAML\n",
    "yaml_path = Path(\"workflow_config.yaml\")\n",
    "config.to_yaml(yaml_path)\n",
    "print(f\"Saved to {yaml_path}\")\n",
    "\n",
    "# View the YAML\n",
    "print(\"\\nYAML contents:\")\n",
    "print(yaml_path.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration Workflow Configuration\n",
      "======================================================================\n",
      "\n",
      "Directories:\n",
      "  Work directory:   /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/work\n",
      "  Output directory: /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/output\n",
      "  Log file:         /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/work/cal_disp.log\n",
      "  Keep relative:    False\n",
      "\n",
      "Input Files:\n",
      "  DISP file:        data/OPERA_L3_DISP-S1_T001-000001-IFG_20240101_20240113_v1.0.nc\n",
      "  Frame ID:         8882\n",
      "  UNR lookup:       data/unr3/grid_latlon_lookup_v0.2.txt\n",
      "  UNR grid dir:     data/unr3\n",
      "\n",
      "Worker Settings:\n",
      "  Workers:          4\n",
      "  Threads/worker:   2\n",
      "  Total threads:    8\n",
      "  Block shape:      (128, 128)\n",
      "\n",
      "Dynamic Ancillary Files:\n",
      "  algorithm_parameters_file: configs/algorithm_parameters.yaml\n",
      "  los_file: data/static_input/OPERA_L3_DISP-S1-STATIC_F08882_20140403_S1A_v1.0_line_of_sight_enu.tif\n",
      "  dem_file: data/static_input/OPERA_L3_DISP-S1-STATIC_F08882_20140403_S1A_v1.0_dem.tif\n",
      "\n",
      "Workflow Status: READY\n",
      "\n",
      "Warnings:\n",
      "  WARNING: Missing files: disp_file\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load from YAML\n",
    "loaded_config = CalibrationWorkflow.from_yaml(yaml_path)\n",
    "print(loaded_config.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Worker Configuration\n",
    "\n",
    "Control parallelism and memory usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workers: 4\n",
      "Threads per worker: 2\n",
      "Total threads: 8\n",
      "\n",
      "Custom: 8 total threads\n"
     ]
    }
   ],
   "source": [
    "from cal_disp.config import WorkerSettings\n",
    "\n",
    "# Default settings (auto-detect CPU count)\n",
    "config.worker_settings = WorkerSettings.create_standard()\n",
    "print(f\"Workers: {config.worker_settings.n_workers}\")\n",
    "print(f\"Threads per worker: {config.worker_settings.threads_per_worker}\")\n",
    "print(f\"Total threads: {config.worker_settings.total_threads}\")\n",
    "\n",
    "# Custom settings for a specific machine\n",
    "config.worker_settings = WorkerSettings(\n",
    "    n_workers=4,\n",
    "    threads_per_worker=2,\n",
    "    block_shape=(512, 512),\n",
    ")\n",
    "print(f\"\\nCustom: {config.worker_settings.total_threads} total threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: File Validation\n",
    "\n",
    "Check which files exist before running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File validation results:\n",
      "  ✗ disp_file: False\n",
      "  ✓ calibration_reference_latlon_file: True\n",
      "  ✓ calibration_reference_grid_dir: True\n",
      "  ✓ algorithm_parameters_file: True\n",
      "  ✓ los_file: True\n",
      "  ✓ dem_file: True\n",
      "\n",
      "Missing files: disp_file\n"
     ]
    }
   ],
   "source": [
    "# Check all input files\n",
    "file_status = config.validate_input_files_exist()\n",
    "\n",
    "print(\"File validation results:\")\n",
    "for filename, info in file_status.items():\n",
    "    status = \"✓\" if info['exists'] else \"✗\"\n",
    "    print(f\"  {status} {filename}: {info['exists']}\")\n",
    "\n",
    "# Get just the missing files\n",
    "missing = config.get_missing_files()\n",
    "if missing:\n",
    "    print(f\"\\nMissing files: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"\\nAll files exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Static Ancillary Files (Optional)\n",
    "\n",
    "For algorithm overrides, custom databases, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cal_disp.config import StaticAncillaryFileGroup\n",
    "\n",
    "config.static_ancillary_options = StaticAncillaryFileGroup(\n",
    "    algorithm_parameters_overrides_json=Path(\"data/custom_params.json\"),\n",
    "    # Add other static files as needed\n",
    ")\n",
    "\n",
    "print(config.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Directory Management\n",
    "\n",
    "Create output directories and set up logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 14:10:57,841 - cal_disp - INFO - Workflow initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work directory: /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/work\n",
      "Output directory: /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/output\n",
      "Log file: /u/aurora-r0/govorcin/01_OPERA/CAL/cal-disp/work/cal_disp.log\n"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "config.create_directories()\n",
    "print(f\"Work directory: {config.work_directory}\")\n",
    "print(f\"Output directory: {config.output_directory}\")\n",
    "print(f\"Log file: {config.log_file}\")\n",
    "\n",
    "# Set up logging\n",
    "import logging\n",
    "\n",
    "logger = config.setup_logging(level=logging.INFO)\n",
    "logger.info(\"Workflow initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example: From Scratch\n",
    "\n",
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete config in one go\n",
    "complete_config = CalibrationWorkflow(\n",
    "    work_directory=Path(\"./processing/work\"),\n",
    "    output_directory=Path(\"./processing/output\"),\n",
    "    input_options=InputFileGroup(\n",
    "        disp_file=Path(\"data/disp.nc\"),\n",
    "        unr_grid_latlon_file=Path('latlon.txt'),\n",
    "        unr_timeseries_dir=Path(\"data/\"),\n",
    "        frame_id=1,\n",
    "        unr_grid_version=\"0.2\",\n",
    "        unr_grid_type=\"constant\",\n",
    "    ),\n",
    "    dynamic_ancillary_options=DynamicAncillaryFileGroup(\n",
    "        algorithm_parameters_file=Path('algorithm.yaml'),\n",
    "        static_dem_file=Path(\"data/dem.tif\"),\n",
    "        static_los_file=Path(\"data/los_enu.tif\"),\n",
    "    ),\n",
    "    worker_settings=WorkerSettings(\n",
    "        n_workers=4,\n",
    "        threads_per_worker=2,\n",
    "    ),\n",
    "    keep_paths_relative=True,  # Keep relative for portability\n",
    ")\n",
    "\n",
    "# Save and verify\n",
    "complete_config.to_yaml(\"production_config.yaml\")\n",
    "print(complete_config.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Resolution\n",
    "\n",
    "By default, paths are resolved to absolute. Control this with `keep_paths_relative`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute paths (default)\n",
    "abs_config = CalibrationWorkflow(\n",
    "    work_directory=Path(\"./work\"),\n",
    "    output_directory=Path(\"./output\"),\n",
    "    keep_paths_relative=False,\n",
    ")\n",
    "print(f\"Work dir: {abs_config.work_directory}\")\n",
    "\n",
    "# Relative paths (for portability)\n",
    "rel_config = CalibrationWorkflow(\n",
    "    work_directory=Path(\"./work\"),\n",
    "    output_directory=Path(\"./output\"),\n",
    "    keep_paths_relative=True,\n",
    ")\n",
    "print(f\"Work dir: {rel_config.work_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "The config system validates at creation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # This will fail - invalid type for n_workers\n",
    "    bad_config = CalibrationWorkflow(\n",
    "        worker_settings=WorkerSettings(n_workers=\"not a number\")\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check readiness before running\n",
    "incomplete_config = CalibrationWorkflow.create_minimal()\n",
    "status = incomplete_config.validate_ready_to_run()\n",
    "\n",
    "if not status['ready']:\n",
    "    print(\"Not ready to run!\")\n",
    "    print(\"Errors:\")\n",
    "    for error in status['errors']:\n",
    "        print(f\"  - {error}\")\n",
    "else:\n",
    "    print(\"Ready to run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command-Line Usage\n",
    "\n",
    "Typical workflow from the command line:\n",
    "\n",
    "```bash\n",
    "# Create a template config\n",
    "python -c \"from cal_disp.config import CalibrationWorkflow; \\\n",
    "           CalibrationWorkflow.create_example().to_yaml('config.yaml')\"\n",
    "\n",
    "# Edit config.yaml with your paths\n",
    "vim config.yaml\n",
    "\n",
    "# Run the workflow\n",
    "cal-disp run config.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips and Best Practices\n",
    "\n",
    "1. **Start with `create_minimal()` or `create_example()`** - don't build configs from scratch\n",
    "2. **Use relative paths** when configs need to be portable across machines\n",
    "3. **Always call `validate_ready_to_run()`** before starting a long job\n",
    "4. **Set up logging early** with `setup_logging()` to catch issues\n",
    "5. **Version control your YAML configs** - they're small and readable\n",
    "6. **Use `summary()` to sanity-check** your configuration before running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Patterns\n",
    "\n",
    "### Pattern 1: Load, Modify, Save\n",
    "\n",
    "```python\n",
    "# Load existing config\n",
    "config = CalibrationWorkflow.from_yaml(\"config.yaml\")\n",
    "\n",
    "# Modify one thing\n",
    "config.worker_settings.n_workers = 8\n",
    "\n",
    "# Save as new config\n",
    "config.to_yaml(\"config_8workers.yaml\")\n",
    "```\n",
    "\n",
    "### Pattern 2: Batch Processing\n",
    "\n",
    "```python\n",
    "# Create configs for multiple frames\n",
    "base_config = CalibrationWorkflow.from_yaml(\"base_config.yaml\")\n",
    "\n",
    "for frame_id in [1, 2, 3, 4]:\n",
    "    config = base_config.model_copy(deep=True)\n",
    "    config.input_options.frame_id = frame_id\n",
    "    config.input_options.disp_file = Path(f\"data/frame_{frame_id}.nc\")\n",
    "    config.output_directory = Path(f\"output/frame_{frame_id}\")\n",
    "    config.to_yaml(f\"config_frame_{frame_id}.yaml\")\n",
    "```\n",
    "\n",
    "### Pattern 3: Conditional Configuration\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "# Different settings for local vs HPC\n",
    "if os.getenv(\"SLURM_JOB_ID\"):\n",
    "    # On HPC cluster\n",
    "    config.worker_settings = WorkerSettings(\n",
    "        n_workers=int(os.getenv(\"SLURM_CPUS_PER_TASK\", 16)),\n",
    "        threads_per_worker=1,\n",
    "    )\n",
    "else:\n",
    "    # Local machine\n",
    "    config.worker_settings = WorkerSettings.create_standard()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- See `docs/tutorials/workflow.ipynb` for running the full calibration workflow\n",
    "- Check the [API docs](https://cal-disp.readthedocs.io/) for all available options\n",
    "- Look at `examples/` directory for real-world configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-cal-disp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
